---
title: "vulcn crawl"
seo:
  title: "vulcn crawl â€” Auto-Discover Forms and Injection Points"
  description: "Automatically crawl web applications to discover forms and injectable inputs. Generate session files for automated security testing with Vulcn."
description: "Auto-discover forms and injection points on a target website"
---

## Usage

```bash
vulcn crawl [url] [options]
```

## Arguments

| Argument | Description                                     | Required |
| -------- | ----------------------------------------------- | -------- |
| `url`    | Target URL (overrides `target` in `.vulcn.yml`) | No       |

## Options

| Option                    | Description                                | Default     |
| ------------------------- | ------------------------------------------ | ----------- |
| `-d, --depth <n>`         | Maximum crawl depth                        | from config |
| `-m, --max-pages <n>`     | Maximum pages to visit                     | from config |
| `-b, --browser <browser>` | Browser to use (chromium, firefox, webkit) | from config |
| `--headless`              | Run in headless mode                       | from config |
| `--no-headless`           | Run with visible browser                   | -           |
| `-t, --timeout <ms>`      | Page timeout in milliseconds               | from config |
| `--no-same-origin`        | Allow following cross-origin links         | -           |
| `--run`                   | Auto-run scans after crawl                 | `false`     |

All options default to values in `.vulcn.yml` under `scan.*` and `crawl.*`.

## Description

The `crawl` command automates the discovery of forms and injectable inputs across a web application. It reads the target from `.vulcn.yml` and generates one session file per discovered form in the `sessions/` directory.

This is essential for **automated scanning** â€” point it at a target, let it discover attack surfaces, and optionally chain directly into scanning with `--run`.

## How It Works

1. Reads target from `.vulcn.yml` (or CLI arg) and crawl settings
2. Visits pages and discovers all links (BFS)
3. Follows links up to `--depth` levels deep
4. Identifies forms and standalone inputs on each page
5. Generates a session file per form with all injectable inputs marked
6. Captures `CapturedRequest` HTTP metadata for each form (used by Tier 1 HTTP fast scan)
7. Saves sessions to `sessions/`
8. Optionally chains into `vulcn run` with `--run`

<Info>
  The `CapturedRequest` metadata enables Tier 1 scanning â€” HTTP-level payload
  testing via `fetch()` at ~50ms/payload. This runs automatically when you
  `vulcn run` a crawled session. See [Browser Driver](/drivers/browser) for
  details.
</Info>

## Examples

### Basic Crawl

```bash
vulcn crawl
```

Reads target and settings from `.vulcn.yml`, crawls the site, saves sessions to `sessions/`.

### Override Target URL

```bash
vulcn crawl https://example.com
```

### Deep Crawl

```bash
vulcn crawl -d 3 -m 50
```

Follow links 3 levels deep, visiting up to 50 pages.

### Crawl â†’ Scan Pipeline

```bash
vulcn crawl --run
```

Crawls the site, then automatically runs security tests on every discovered form using the payload types configured in `.vulcn.yml`.

### Authenticated Crawl

Crawl pages behind login using stored credentials:

```bash
# First store credentials
vulcn store admin password

# Then crawl â€” auth is auto-discovered from auth/state.enc
vulcn crawl
```

When `auth/state.enc` is found, Vulcn will:

1. Decrypt the credentials file using `VULCN_KEY` or an interactive prompt
2. Launch a browser and navigate to the login URL
3. Auto-detect the login form and fill credentials
4. Capture the browser's storage state (cookies + localStorage)
5. Use the authenticated context for crawling

### Benchmarking Against DVWA

```bash
# Start DVWA
docker run -d -p 8080:80 vulnerables/web-dvwa

# Initialize project
vulcn init http://localhost:8080

# Store DVWA credentials
vulcn store admin password

# Authenticated crawl + scan
vulcn crawl --run
```

<Tip>
  The `--run` flag is the fastest way to go from zero to a full security
  assessment. It chains crawling directly into scanning without any manual
  session management.
</Tip>

## Output

The crawl command generates session files named by page and form:

```bash
âœ” Crawl complete: 5 pages, 3 forms found
âœ” Saved 3 session(s) to sessions/

ðŸ“‹ Generated Sessions

  1. Crawl: /search â€” form 1 (query)
     1 injectable input(s), 3 steps

  2. Crawl: /login â€” form 1 (username, password)
     2 injectable input(s), 4 steps

  3. Crawl: /contact â€” form 1 (name, email, message)
     3 injectable input(s), 5 steps

Next steps:
  vulcn run
```

### Generated Session Format

Each session file contains navigating to the page, filling each injectable input, and submitting the form:

```yaml
name: "Crawl: /search â€” form 1 (query)"
driver: browser
driverConfig:
  startUrl: https://example.com/search
  browser: chromium
  headless: true
steps:
  - id: step-1
    type: browser.navigate
    url: https://example.com/search
  - id: step-2
    type: browser.input
    selector: 'form:nth-of-type(1) [name="query"]'
    value: test
    injectable: true
  - id: step-3
    type: browser.click
    selector: form:nth-of-type(1) button
```

## See Also

- [vulcn store](/cli/store) â€” Store credentials for authenticated crawling
- [vulcn run](/cli/run) â€” Run security tests on generated sessions
- [vulcn record](/cli/record) â€” Manually record browser interactions
